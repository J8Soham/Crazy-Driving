{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: highway_env in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (1.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (1.24.3)\n",
      "Requirement already satisfied: pygame>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (2.5.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (3.9.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (2.2.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from highway_env) (1.13.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium>=1.0.0a2->highway_env) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium>=1.0.0a2->highway_env) (4.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->highway_env) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->highway_env) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->highway_env) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->highway_env) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install highway_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import highway_env\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = gymnasium.make(\"highway-v0\", render_mode='rgb_array')\n",
    "# pprint.pprint(env.unwrapped.config)\n",
    "env.unwrapped.config[\"lanes_count\"] = 3\n",
    "env.unwrapped.config[\"duration\"] = 10\n",
    "env.unwrapped.config[\"vehicles_density\"] = 2 # 3\n",
    "env.unwrapped.config[\"vehicles_count\"] = 10\n",
    "\n",
    "env.unwrapped.config[\"action\"][\"type\"] = \"DiscreteAction\"\n",
    "ACTION_SIZE = 9\n",
    "# ACTION_SIZE = 5\n",
    "observation = {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 5,\n",
    "        \"features\": [\"x\", \"y\", \"vx\", \"vy\", \"cos_h\"],\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-20, 20],\n",
    "            \"vy\": [-20, 20]\n",
    "        },\n",
    "        \"absolute\": True,\n",
    "        # \"absolute\": True,\n",
    "        \"order\": \"sorted\"\n",
    "    }\n",
    "env.unwrapped.config[\"observation\"] = observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=50):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.norm_1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.norm_2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.layer_3 = nn.Linear(hidden_size, output_size)\n",
    "        self.norm_3 = nn.BatchNorm1d(output_size)\n",
    "\n",
    "    def forward(self, obs, batch_size=1):\n",
    "        batch_norm_on = batch_size != 1\n",
    "        if obs is None:\n",
    "            retval = torch.tensor([[1/self.output_size] * self.output_size] * batch_size)\n",
    "            return retval\n",
    "        \n",
    "       \n",
    "        x = torch.tensor(obs)\n",
    "        x = x.view(-1, self.input_size)\n",
    "\n",
    "\n",
    "        x = self.layer_1(x)\n",
    "        if batch_norm_on:\n",
    "            x = self.norm_1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.layer_2(x)\n",
    "        if batch_norm_on:\n",
    "            x = self.norm_2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.layer_3(x)\n",
    "        if batch_norm_on:\n",
    "            x = self.norm_3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity=1000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(args)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        for i, memory in enumerate(batch):\n",
    "            states.append(torch.tensor(memory[0]))\n",
    "            actions.append(torch.tensor(memory[1]))\n",
    "            rewards.append(torch.tensor(memory[2]))\n",
    "        states = torch.stack(states)\n",
    "        actions = torch.stack(actions)\n",
    "        rewards = torch.stack(rewards)\n",
    "            \n",
    "        return states, actions, rewards\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(obs, policy_net):\n",
    "    if obs is None:\n",
    "        return 0\n",
    "    policy = policy_net(obs)\n",
    "    policy = policy.detach().numpy().flatten()\n",
    "    return np.random.choice(len(policy), p=policy)\n",
    "    # policy.numpy()\n",
    "    # return torch.argmax(policy, dim=1).item()\n",
    "\n",
    "def optimize_model(policy_net, value_net, memory, BATCH_SIZE, GAMMA, optimizer):\n",
    "\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    # print('learn')\n",
    "    state_batch, action_batch, reward_batch = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "\n",
    "    state_action_values = policy_net(state_batch, batch_size=BATCH_SIZE).gather(1, action_batch.unsqueeze(1))\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "\n",
    "    next_state_values = torch.max(value_net(state_batch, batch_size=BATCH_SIZE), dim=1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    print(f'Loss: {loss:.2f}')\n",
    "    # [batch_size, 1, 1]\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "policy: tensor([[0.1246, 0.1493, 0.4039, 0.2568, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "policy: tensor([[0.1245, 0.1493, 0.4040, 0.2568, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "epoch: 6\n",
      "policy: tensor([[0.1247, 0.1493, 0.4038, 0.2569, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "policy: tensor([[0.1246, 0.1492, 0.4041, 0.2568, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "epoch: 7\n",
      "policy: tensor([[0.1247, 0.1493, 0.4038, 0.2568, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "policy: tensor([[0.1246, 0.1493, 0.4041, 0.2567, 0.0653]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2959, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.50\n",
      "policy: tensor([[0.1230, 0.1475, 0.3932, 0.2700, 0.0662]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1181, 0.1459, 0.3884, 0.2802, 0.0674]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "epoch: 8\n",
      "policy: tensor([[0.1133, 0.1429, 0.3921, 0.2849, 0.0667]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2960, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1122, 0.1406, 0.3965, 0.2844, 0.0663]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "policy: tensor([[0.1123, 0.1389, 0.4005, 0.2833, 0.0650]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1858, 0.2967, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n",
      "policy: tensor([[0.1112, 0.1357, 0.4044, 0.2857, 0.0630]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1592, 0.1862, 0.2964, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "epoch: 10\n",
      "policy: tensor([[0.1093, 0.1336, 0.4064, 0.2897, 0.0609]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\n",
      "policy: tensor([[0.1071, 0.1327, 0.4063, 0.2945, 0.0594]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "policy: tensor([[0.1053, 0.1322, 0.4055, 0.2986, 0.0584]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1044, 0.1321, 0.4053, 0.3002, 0.0580]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1858, 0.2964, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n",
      "policy: tensor([[0.1036, 0.1311, 0.4038, 0.3038, 0.0577]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\n",
      "policy: tensor([[0.1028, 0.1306, 0.4042, 0.3049, 0.0575]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "epoch: 13\n",
      "policy: tensor([[0.1030, 0.1315, 0.4009, 0.3074, 0.0571]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2963, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1032, 0.1329, 0.3967, 0.3097, 0.0574]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "policy: tensor([[0.1024, 0.1326, 0.3923, 0.3155, 0.0571]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n",
      "policy: tensor([[0.1024, 0.1335, 0.3895, 0.3175, 0.0571]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "policy: tensor([[0.1019, 0.1343, 0.3859, 0.3211, 0.0568]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1017, 0.1357, 0.3835, 0.3228, 0.0563]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2958, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "policy: tensor([[0.1015, 0.1363, 0.3837, 0.3225, 0.0559]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2960, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1010, 0.1375, 0.3831, 0.3230, 0.0555]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2960, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "epoch: 15\n",
      "policy: tensor([[0.1005, 0.1387, 0.3823, 0.3237, 0.0548]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2964, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16\n",
      "policy: tensor([[0.0994, 0.1390, 0.3795, 0.3280, 0.0541]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.24\n",
      "policy: tensor([[0.0990, 0.1390, 0.3775, 0.3305, 0.0540]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2962, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0986, 0.1402, 0.3765, 0.3315, 0.0532]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "policy: tensor([[0.0983, 0.1409, 0.3727, 0.3354, 0.0526]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\n",
      "policy: tensor([[0.0984, 0.1395, 0.3736, 0.3365, 0.0520]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.23\n",
      "policy: tensor([[0.0978, 0.1390, 0.3710, 0.3409, 0.0512]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2959, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\n",
      "policy: tensor([[0.0990, 0.1370, 0.3678, 0.3456, 0.0506]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2962, 0.2116, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.26\n",
      "epoch: 19\n",
      "policy: tensor([[0.0997, 0.1379, 0.3672, 0.3453, 0.0500]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1000, 0.1388, 0.3667, 0.3449, 0.0497]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.26\n",
      "policy: tensor([[0.1000, 0.1387, 0.3694, 0.3426, 0.0494]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.1004, 0.1386, 0.3676, 0.3447, 0.0487]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "epoch: 20\n",
      "policy: tensor([[0.1005, 0.1382, 0.3696, 0.3435, 0.0481]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0996, 0.1393, 0.3731, 0.3403, 0.0477]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "policy: tensor([[0.0986, 0.1395, 0.3783, 0.3366, 0.0470]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21\n",
      "policy: tensor([[0.0978, 0.1367, 0.3829, 0.3366, 0.0459]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.22\n",
      "policy: tensor([[0.0983, 0.1393, 0.3818, 0.3342, 0.0464]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2958, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22\n",
      "policy: tensor([[0.0964, 0.1377, 0.3841, 0.3369, 0.0449]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "policy: tensor([[0.0951, 0.1392, 0.3836, 0.3374, 0.0447]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2960, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0939, 0.1406, 0.3858, 0.3356, 0.0442]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "policy: tensor([[0.0936, 0.1396, 0.3875, 0.3353, 0.0440]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0923, 0.1401, 0.3885, 0.3356, 0.0435]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "policy: tensor([[0.0920, 0.1429, 0.3873, 0.3340, 0.0438]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0913, 0.1424, 0.3882, 0.3347, 0.0434]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.27\n",
      "policy: tensor([[0.0906, 0.1423, 0.3882, 0.3357, 0.0431]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0899, 0.1424, 0.3867, 0.3382, 0.0428]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2119, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "policy: tensor([[0.0906, 0.1449, 0.3813, 0.3397, 0.0435]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23\n",
      "policy: tensor([[0.0913, 0.1457, 0.3727, 0.3466, 0.0436]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "policy: tensor([[0.0922, 0.1470, 0.3667, 0.3502, 0.0439]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2959, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0922, 0.1478, 0.3621, 0.3531, 0.0449]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2955, 0.2120, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "policy: tensor([[0.0940, 0.1522, 0.3480, 0.3611, 0.0448]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24\n",
      "policy: tensor([[0.0929, 0.1508, 0.3579, 0.3543, 0.0441]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2122, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "policy: tensor([[0.0928, 0.1523, 0.3545, 0.3560, 0.0444]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\n",
      "policy: tensor([[0.0938, 0.1533, 0.3502, 0.3582, 0.0445]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2964, 0.2118, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n",
      "epoch: 26\n",
      "policy: tensor([[0.0930, 0.1544, 0.3546, 0.3532, 0.0447]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0927, 0.1572, 0.3480, 0.3570, 0.0451]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "epoch: 27\n",
      "policy: tensor([[0.0932, 0.1556, 0.3494, 0.3579, 0.0439]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2961, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28\n",
      "policy: tensor([[0.0930, 0.1561, 0.3551, 0.3520, 0.0437]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "epoch: 29\n",
      "policy: tensor([[0.0945, 0.1588, 0.3504, 0.3519, 0.0444]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\n",
      "policy: tensor([[0.0953, 0.1596, 0.3409, 0.3601, 0.0440]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.45\n",
      "epoch: 31\n",
      "policy: tensor([[0.0952, 0.1579, 0.3553, 0.3483, 0.0434]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2119, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0955, 0.1586, 0.3557, 0.3464, 0.0438]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "policy: tensor([[0.0961, 0.1565, 0.3569, 0.3468, 0.0437]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2964, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32\n",
      "policy: tensor([[0.0953, 0.1546, 0.3639, 0.3426, 0.0437]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "epoch: 33\n",
      "policy: tensor([[0.0965, 0.1506, 0.3685, 0.3406, 0.0438]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0960, 0.1507, 0.3705, 0.3388, 0.0441]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2958, 0.2118, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "epoch: 34\n",
      "policy: tensor([[0.0961, 0.1489, 0.3725, 0.3392, 0.0433]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0943, 0.1493, 0.3693, 0.3439, 0.0432]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "policy: tensor([[0.0930, 0.1480, 0.3687, 0.3471, 0.0432]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n",
      "policy: tensor([[0.0941, 0.1436, 0.3785, 0.3413, 0.0425]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "policy: tensor([[0.0936, 0.1428, 0.3792, 0.3417, 0.0428]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0927, 0.1400, 0.3803, 0.3447, 0.0422]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "epoch: 36\n",
      "policy: tensor([[0.0940, 0.1391, 0.3761, 0.3485, 0.0423]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2960, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37\n",
      "policy: tensor([[0.0938, 0.1354, 0.3827, 0.3467, 0.0415]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2961, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "epoch: 38\n",
      "policy: tensor([[0.0938, 0.1337, 0.3890, 0.3426, 0.0409]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0947, 0.1331, 0.3905, 0.3410, 0.0407]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "policy: tensor([[0.0957, 0.1323, 0.3909, 0.3408, 0.0404]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39\n",
      "policy: tensor([[0.0970, 0.1286, 0.4015, 0.3331, 0.0398]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1592, 0.1862, 0.2965, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "policy: tensor([[0.0962, 0.1296, 0.3909, 0.3442, 0.0391]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1858, 0.2965, 0.2121, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0959, 0.1295, 0.3920, 0.3437, 0.0389]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1858, 0.2966, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.25\n",
      "epoch: 40\n",
      "policy: tensor([[0.0969, 0.1255, 0.4013, 0.3387, 0.0377]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0962, 0.1256, 0.4032, 0.3377, 0.0373]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2962, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "epoch: 41\n",
      "policy: tensor([[0.0965, 0.1243, 0.4093, 0.3328, 0.0371]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0957, 0.1257, 0.4058, 0.3358, 0.0371]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2958, 0.2119, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "policy: tensor([[0.0948, 0.1246, 0.4066, 0.3375, 0.0365]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2958, 0.2119, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42\n",
      "policy: tensor([[0.0942, 0.1233, 0.4123, 0.3343, 0.0359]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "policy: tensor([[0.0919, 0.1244, 0.4139, 0.3336, 0.0361]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43\n",
      "policy: tensor([[0.0901, 0.1232, 0.4222, 0.3290, 0.0355]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "policy: tensor([[0.0866, 0.1225, 0.4272, 0.3286, 0.0352]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0846, 0.1217, 0.4388, 0.3196, 0.0353]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.25\n",
      "epoch: 44\n",
      "policy: tensor([[0.0816, 0.1204, 0.4394, 0.3240, 0.0346]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\n",
      "policy: tensor([[0.0794, 0.1195, 0.4461, 0.3210, 0.0341]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "policy: tensor([[0.0768, 0.1201, 0.4509, 0.3184, 0.0338]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0748, 0.1222, 0.4538, 0.3152, 0.0340]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.43\n",
      "policy: tensor([[0.0741, 0.1239, 0.4508, 0.3169, 0.0343]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1859, 0.2965, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48\n",
      "policy: tensor([[0.0723, 0.1216, 0.4585, 0.3143, 0.0333]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "policy: tensor([[0.0709, 0.1236, 0.4517, 0.3202, 0.0336]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0705, 0.1219, 0.4622, 0.3120, 0.0335]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1596, 0.1865, 0.2955, 0.2118, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n",
      "epoch: 49\n",
      "policy: tensor([[0.0676, 0.1215, 0.4617, 0.3167, 0.0325]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "policy: tensor([[0.0665, 0.1209, 0.4627, 0.3177, 0.0321]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "epoch: 51\n",
      "policy: tensor([[0.0659, 0.1218, 0.4684, 0.3118, 0.0321]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2960, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52\n",
      "policy: tensor([[0.0659, 0.1228, 0.4711, 0.3082, 0.0322]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n",
      "epoch: 53\n",
      "policy: tensor([[0.0634, 0.1211, 0.4760, 0.3087, 0.0309]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2962, 0.2121, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0637, 0.1216, 0.4778, 0.3058, 0.0311]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.45\n",
      "epoch: 54\n",
      "policy: tensor([[0.0650, 0.1196, 0.4947, 0.2893, 0.0314]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1864, 0.2962, 0.2117, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0647, 0.1204, 0.4944, 0.2892, 0.0314]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n",
      "epoch: 55\n",
      "policy: tensor([[0.0637, 0.1177, 0.4960, 0.2921, 0.0305]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0660, 0.1221, 0.4713, 0.3087, 0.0320]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n",
      "epoch: 56\n",
      "policy: tensor([[0.0632, 0.1188, 0.4977, 0.2898, 0.0304]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0639, 0.1205, 0.4898, 0.2948, 0.0310]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2960, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "epoch: 57\n",
      "policy: tensor([[0.0639, 0.1158, 0.5117, 0.2782, 0.0304]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0640, 0.1170, 0.5161, 0.2722, 0.0308]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.41\n",
      "epoch: 58\n",
      "policy: tensor([[0.0620, 0.1136, 0.5433, 0.2516, 0.0296]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2960, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59\n",
      "policy: tensor([[0.0639, 0.1152, 0.5293, 0.2609, 0.0307]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "policy: tensor([[0.0642, 0.1151, 0.5316, 0.2583, 0.0307]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2965, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60\n",
      "policy: tensor([[0.0652, 0.1130, 0.5420, 0.2495, 0.0303]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.48\n",
      "policy: tensor([[0.0656, 0.1108, 0.5546, 0.2388, 0.0303]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2960, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61\n",
      "policy: tensor([[0.0658, 0.1093, 0.5592, 0.2360, 0.0297]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2964, 0.2118, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n",
      "epoch: 62\n",
      "policy: tensor([[0.0671, 0.1093, 0.5598, 0.2340, 0.0298]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0699, 0.1089, 0.5592, 0.2319, 0.0301]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2959, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n",
      "epoch: 63\n",
      "policy: tensor([[0.0699, 0.1038, 0.5818, 0.2154, 0.0292]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1863, 0.2962, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0705, 0.1066, 0.5761, 0.2175, 0.0292]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n",
      "policy: tensor([[0.0684, 0.1070, 0.5754, 0.2209, 0.0283]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0701, 0.1060, 0.5824, 0.2133, 0.0283]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2961, 0.2121, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n",
      "policy: tensor([[0.0696, 0.1045, 0.5874, 0.2108, 0.0277]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0721, 0.1033, 0.5908, 0.2059, 0.0279]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n",
      "policy: tensor([[0.0726, 0.1018, 0.5921, 0.2059, 0.0276]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0730, 0.0994, 0.5972, 0.2030, 0.0273]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1863, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n",
      "epoch: 64\n",
      "policy: tensor([[0.0725, 0.0983, 0.5971, 0.2050, 0.0271]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65\n",
      "policy: tensor([[0.0710, 0.0960, 0.5987, 0.2077, 0.0266]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "policy: tensor([[0.0710, 0.0970, 0.5910, 0.2142, 0.0268]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2962, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0715, 0.0960, 0.5930, 0.2130, 0.0265]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1858, 0.2965, 0.2121, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "policy: tensor([[0.0715, 0.0959, 0.5910, 0.2153, 0.0263]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2964, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0708, 0.0969, 0.5869, 0.2192, 0.0262]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "epoch: 66\n",
      "policy: tensor([[0.0688, 0.0967, 0.5868, 0.2220, 0.0257]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0674, 0.0977, 0.5812, 0.2279, 0.0257]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1859, 0.2965, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.25\n",
      "policy: tensor([[0.0658, 0.0957, 0.5870, 0.2264, 0.0252]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1858, 0.2965, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67\n",
      "policy: tensor([[0.0686, 0.0965, 0.5780, 0.2311, 0.0258]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1864, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n",
      "epoch: 68\n",
      "policy: tensor([[0.0683, 0.0977, 0.5705, 0.2378, 0.0257]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0682, 0.1001, 0.5662, 0.2394, 0.0260]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2959, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "epoch: 69\n",
      "policy: tensor([[0.0713, 0.0983, 0.5627, 0.2414, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0685, 0.0985, 0.5668, 0.2402, 0.0260]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n",
      "epoch: 70\n",
      "policy: tensor([[0.0693, 0.0969, 0.5669, 0.2407, 0.0262]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71\n",
      "policy: tensor([[0.0675, 0.0959, 0.5732, 0.2375, 0.0259]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "epoch: 72\n",
      "policy: tensor([[0.0672, 0.0964, 0.5703, 0.2399, 0.0262]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2963, 0.2119, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73\n",
      "policy: tensor([[0.0683, 0.0962, 0.5681, 0.2406, 0.0267]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2960, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "policy: tensor([[0.0676, 0.0976, 0.5677, 0.2402, 0.0269]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2958, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74\n",
      "policy: tensor([[0.0644, 0.0944, 0.5830, 0.2325, 0.0257]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "policy: tensor([[0.0653, 0.0940, 0.5678, 0.2463, 0.0266]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1859, 0.2964, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0645, 0.0925, 0.5664, 0.2498, 0.0267]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n",
      "policy: tensor([[0.0647, 0.0887, 0.5691, 0.2504, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2959, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75\n",
      "policy: tensor([[0.0641, 0.0877, 0.5674, 0.2538, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "policy: tensor([[0.0639, 0.0868, 0.5625, 0.2595, 0.0273]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1596, 0.1862, 0.2960, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76\n",
      "policy: tensor([[0.0635, 0.0844, 0.5709, 0.2541, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "epoch: 77\n",
      "policy: tensor([[0.0633, 0.0838, 0.5704, 0.2553, 0.0271]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0623, 0.0831, 0.5762, 0.2514, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2958, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "policy: tensor([[0.0607, 0.0828, 0.5871, 0.2431, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1858, 0.2966, 0.2121, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0601, 0.0811, 0.5883, 0.2442, 0.0262]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1859, 0.2966, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "policy: tensor([[0.0600, 0.0816, 0.5992, 0.2328, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0598, 0.0810, 0.6048, 0.2280, 0.0263]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2962, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.45\n",
      "policy: tensor([[0.0603, 0.0800, 0.6101, 0.2232, 0.0263]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0614, 0.0792, 0.6172, 0.2157, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2962, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "policy: tensor([[0.0619, 0.0793, 0.6203, 0.2122, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2962, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0621, 0.0794, 0.6216, 0.2108, 0.0261]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.27\n",
      "policy: tensor([[0.0628, 0.0796, 0.6215, 0.2100, 0.0261]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78\n",
      "policy: tensor([[0.0629, 0.0817, 0.6137, 0.2153, 0.0264]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1860, 0.2960, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "epoch: 79\n",
      "policy: tensor([[0.0647, 0.0820, 0.6065, 0.2202, 0.0266]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2120, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0658, 0.0849, 0.6017, 0.2205, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2962, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.25\n",
      "policy: tensor([[0.0658, 0.0857, 0.6063, 0.2152, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1865, 0.2955, 0.2120, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0660, 0.0869, 0.6075, 0.2125, 0.0270]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1865, 0.2955, 0.2120, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.36\n",
      "epoch: 80\n",
      "policy: tensor([[0.0641, 0.0838, 0.6164, 0.2098, 0.0258]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2964, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81\n",
      "policy: tensor([[0.0635, 0.0842, 0.6345, 0.1928, 0.0251]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n",
      "policy: tensor([[0.0670, 0.0869, 0.6093, 0.2101, 0.0267]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82\n",
      "policy: tensor([[0.0658, 0.0840, 0.6283, 0.1964, 0.0254]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2960, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.24\n",
      "epoch: 83\n",
      "policy: tensor([[0.0701, 0.0867, 0.5896, 0.2262, 0.0273]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84\n",
      "policy: tensor([[0.0699, 0.0879, 0.5878, 0.2271, 0.0273]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2964, 0.2119, 0.1462]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.27\n",
      "policy: tensor([[0.0717, 0.0903, 0.5765, 0.2337, 0.0277]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0715, 0.0916, 0.5742, 0.2345, 0.0281]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2959, 0.2121, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "policy: tensor([[0.0721, 0.0900, 0.5746, 0.2353, 0.0281]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1596, 0.1865, 0.2955, 0.2119, 0.1465]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0721, 0.0925, 0.5622, 0.2452, 0.0280]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1859, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.31\n",
      "policy: tensor([[0.0722, 0.0889, 0.5675, 0.2440, 0.0275]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0737, 0.0886, 0.5646, 0.2454, 0.0278]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2962, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.33\n",
      "epoch: 85\n",
      "policy: tensor([[0.0734, 0.0886, 0.5576, 0.2527, 0.0278]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0729, 0.0902, 0.5561, 0.2529, 0.0279]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1860, 0.2963, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "policy: tensor([[0.0721, 0.0882, 0.5497, 0.2623, 0.0277]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86\n",
      "policy: tensor([[0.0727, 0.0863, 0.5587, 0.2547, 0.0275]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.28\n",
      "policy: tensor([[0.0724, 0.0868, 0.5540, 0.2591, 0.0276]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87\n",
      "policy: tensor([[0.0704, 0.0835, 0.5677, 0.2517, 0.0266]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n",
      "epoch: 88\n",
      "policy: tensor([[0.0707, 0.0845, 0.5614, 0.2566, 0.0268]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2962, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89\n",
      "policy: tensor([[0.0726, 0.0847, 0.5592, 0.2563, 0.0272]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1860, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.41\n",
      "epoch: 90\n",
      "policy: tensor([[0.0709, 0.0824, 0.5623, 0.2579, 0.0265]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91\n",
      "policy: tensor([[0.0738, 0.0831, 0.5596, 0.2562, 0.0273]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2964, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "epoch: 92\n",
      "policy: tensor([[0.0742, 0.0814, 0.5688, 0.2486, 0.0269]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1864, 0.2960, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93\n",
      "policy: tensor([[0.0737, 0.0833, 0.5587, 0.2571, 0.0272]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2963, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "policy: tensor([[0.0739, 0.0858, 0.5450, 0.2675, 0.0278]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1859, 0.2964, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94\n",
      "policy: tensor([[0.0738, 0.0834, 0.5513, 0.2638, 0.0277]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1862, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.42\n",
      "policy: tensor([[0.0742, 0.0843, 0.5572, 0.2564, 0.0278]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1863, 0.2961, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95\n",
      "policy: tensor([[0.0730, 0.0832, 0.5663, 0.2501, 0.0275]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1862, 0.2962, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "policy: tensor([[0.0725, 0.0836, 0.5577, 0.2586, 0.0277]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2959, 0.2119, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96\n",
      "policy: tensor([[0.0736, 0.0829, 0.5579, 0.2578, 0.0279]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2962, 0.2118, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.35\n",
      "policy: tensor([[0.0732, 0.0830, 0.5583, 0.2576, 0.0280]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1863, 0.2961, 0.2118, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97\n",
      "policy: tensor([[0.0742, 0.0858, 0.5428, 0.2684, 0.0288]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2961, 0.2121, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n",
      "policy: tensor([[0.0735, 0.0875, 0.5365, 0.2734, 0.0291]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1861, 0.2959, 0.2121, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: tensor([[0.0746, 0.0885, 0.5259, 0.2811, 0.0298]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2963, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.37\n",
      "policy: tensor([[0.0715, 0.0861, 0.5499, 0.2640, 0.0285]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1595, 0.1862, 0.2960, 0.2120, 0.1464]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98\n",
      "policy: tensor([[0.0721, 0.0857, 0.5550, 0.2586, 0.0287]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1593, 0.1861, 0.2964, 0.2119, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.21\n",
      "epoch: 99\n",
      "policy: tensor([[0.0704, 0.0875, 0.5537, 0.2598, 0.0286]], grad_fn=<SoftmaxBackward0>)\n",
      "value: tensor([[0.1594, 0.1861, 0.2962, 0.2120, 0.1463]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n",
      "/var/folders/23/10qz4m5j15qdd0tp45tczpw40000gn/T/ipykernel_98788/1276593815.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(obs)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "OBS_SIZE = env.unwrapped.config[\"observation\"][\"vehicles_count\"] * len(env.unwrapped.config[\"observation\"][\"features\"])\n",
    "env.unwrapped.config[\"duration\"] = 20\n",
    "\n",
    "EPOCHS = 100\n",
    "batch_size = 16\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "LR = 1e-2\n",
    "\n",
    "policy_net = Model(OBS_SIZE, ACTION_SIZE)\n",
    "value_net = Model(OBS_SIZE, ACTION_SIZE)\n",
    "optimizer = torch.optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "\n",
    "\n",
    "all_parameters = list(policy_net.parameters()) + list(value_net.parameters())\n",
    "optimizer_random = torch.optim.Adam(all_parameters, lr=0.1)\n",
    "\n",
    "env.reset()\n",
    "# while(True):\n",
    "#     env.render()\n",
    "\n",
    "memory = ReplayMemory()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch: {epoch}')\n",
    "    env.reset()\n",
    "    obs = None\n",
    "    done = truncated = False\n",
    "    \n",
    "    total_reward = 0\n",
    "    while not (done or truncated):\n",
    "        action = select_action(obs, policy_net)\n",
    "        next_obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        if info[\"rewards\"][\"on_road_reward\"] == 0:\n",
    "            pass# reward -= 10\n",
    "        # \"features\": [\"x\", \"y\", \"vx\", \"vy\", \"cos_h\"],\n",
    "        # reward += next_obs[0][1] * 10\n",
    "        if done or truncated:\n",
    "            break\n",
    "        if obs is not None:\n",
    "            # print(f'sub: {abs(next_obs[0][4] - obs[0][4])}')\n",
    "            # reward -= abs(next_obs[0][4] - obs[0][4]) * 0.2\n",
    "            memory.push(obs, action, reward)\n",
    "        obs = next_obs\n",
    "        \n",
    "        total_reward += reward\n",
    "        # print(total_reward)\n",
    "        \n",
    "        if epoch < 5: # 5\n",
    "            target = torch.Tensor([[1 / ACTION_SIZE] * ACTION_SIZE])\n",
    "            policy = policy_net(obs)\n",
    "            values = value_net(obs)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            loss_policy = criterion(policy, target)\n",
    "            \n",
    "            loss_values = criterion(policy, values)\n",
    "            loss = loss_policy + loss_values\n",
    "            optimizer_random.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(f'policy: {policy_net(obs)}')\n",
    "            print(f'value: {value_net(obs)}')\n",
    "            optimize_model(policy_net, value_net, memory, batch_size, GAMMA, optimizer)\n",
    "\n",
    "            value_net_state_dict = value_net.state_dict()\n",
    "            policy_net_state_dict = policy_net.state_dict()\n",
    "            for key in policy_net_state_dict:\n",
    "                value_net_state_dict[key] = value_net_state_dict[key]*TAU + value_net_state_dict[key]*(1-TAU)\n",
    "            value_net.load_state_dict(value_net_state_dict)\n",
    "            env.render()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0\n",
      "0 8.0\n",
      "1 1.7637636065483093\n",
      "2 6.509786248207092\n",
      "3 1.7637636065483093\n",
      "4 6.509786248207092\n",
      "5 1.7637636065483093\n",
      "6 4.863429844379425\n",
      "7 6.509786248207092\n",
      "8 8.0\n",
      "9 1.7637636065483093\n",
      "\n",
      "0 1.4644529819488525\n",
      "1 1.4755589962005615\n",
      "2 1.4750087559223175\n",
      "3 1.4755589962005615\n",
      "4 1.4750087559223175\n",
      "5 1.4755589962005615\n",
      "6 1.48556450009346\n",
      "7 1.4750087559223175\n",
      "8 1.4644529819488525\n",
      "9 1.4755589962005615\n",
      "\n",
      "Best model_num: 0 | score: 9.464452981948853\n",
      "\n",
      "Generation: 1\n",
      "0 1.6037171483039856\n",
      "1 1.6037171483039856\n",
      "2 1.6037171483039856\n",
      "3 1.6037171483039856\n",
      "4 1.6037171483039856\n",
      "5 1.6037171483039856\n",
      "6 1.6037171483039856\n",
      "7 1.6037171483039856\n",
      "8 1.6037171483039856\n",
      "9 1.6037171483039856\n",
      "\n",
      "0 4.617260575294495\n",
      "1 4.617260575294495\n",
      "2 4.617260575294495\n",
      "3 4.617260575294495\n",
      "4 4.617260575294495\n",
      "5 4.617260575294495\n",
      "6 4.617260575294495\n",
      "7 4.617260575294495\n",
      "8 4.617260575294495\n",
      "9 4.617260575294495\n",
      "\n",
      "Best model_num: 0 | score: 6.22097772359848\n",
      "\n",
      "Generation: 2\n",
      "0 9.0\n",
      "1 9.0\n",
      "2 9.0\n",
      "3 9.0\n",
      "4 9.0\n",
      "5 9.0\n",
      "6 9.0\n",
      "7 9.0\n",
      "8 9.0\n",
      "9 9.0\n",
      "\n",
      "0 9.0\n",
      "1 9.0\n",
      "2 9.0\n",
      "3 9.0\n",
      "4 9.0\n",
      "5 9.0\n",
      "6 9.0\n",
      "7 9.0\n",
      "8 9.0\n",
      "9 9.0\n",
      "\n",
      "Best model_num: 0 | score: 18.0\n",
      "\n",
      "Generation: 3\n",
      "0 1.5132026672363281\n",
      "1 1.5132026672363281\n",
      "2 1.5132026672363281\n",
      "3 1.5132026672363281\n",
      "4 1.5132026672363281\n",
      "5 1.5132026672363281\n",
      "6 1.5132026672363281\n",
      "7 1.5132026672363281\n",
      "8 1.5132026672363281\n",
      "9 1.5132026672363281\n",
      "\n",
      "0 1.5709002614021301\n",
      "1 1.5709002614021301\n",
      "2 1.5709002614021301\n",
      "3 1.5709002614021301\n",
      "4 1.5709002614021301\n",
      "5 1.5709002614021301\n",
      "6 1.5709002614021301\n",
      "7 1.5709002614021301\n",
      "8 1.5709002614021301\n",
      "9 1.5709002614021301\n",
      "\n",
      "Best model_num: 0 | score: 3.0841029286384583\n",
      "\n",
      "Generation: 4\n",
      "0 1.4644529819488525\n",
      "1 1.4644529819488525\n",
      "2 1.4644529819488525\n",
      "3 1.4644529819488525\n",
      "4 1.4644529819488525\n",
      "5 1.4644529819488525\n",
      "6 1.4644529819488525\n",
      "7 1.4644529819488525\n",
      "8 1.4644529819488525\n",
      "9 1.4644529819488525\n",
      "\n",
      "0 1.7181596159934998\n",
      "1 1.7181596159934998\n",
      "2 1.7181596159934998\n",
      "3 1.7181596159934998\n",
      "4 1.7181596159934998\n",
      "5 1.7181596159934998\n",
      "6 1.7181596159934998\n",
      "7 1.7181596159934998\n",
      "8 1.7181596159934998\n",
      "9 1.7181596159934998\n",
      "\n",
      "Best model_num: 0 | score: 3.1826125979423523\n",
      "\n",
      "Generation: 5\n",
      "0 5.380712538957596\n",
      "1 5.380712538957596\n",
      "2 5.380712538957596\n",
      "3 5.380712538957596\n",
      "4 5.380712538957596\n",
      "5 5.380712538957596\n",
      "6 5.380712538957596\n",
      "7 5.380712538957596\n",
      "8 5.380712538957596\n",
      "9 5.380712538957596\n",
      "\n",
      "0 11.0\n",
      "1 11.0\n",
      "2 11.0\n",
      "3 "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(probabilities)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# action = np.random.choice(ACTION_SIZE, p=probabilities)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_road_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# reward -= 10\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:240\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[1;32m    243\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:280\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# Automatically render intermediate simulation steps if a viewer has been launched\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Ignored if the rendering is done offscreen\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    278\u001b[0m         frame \u001b[38;5;241m<\u001b[39m frames \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    279\u001b[0m     ):  \u001b[38;5;66;03m# Last frame will be rendered through env.render() as usual\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_automatic_rendering\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_auto_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:340\u001b[0m, in \u001b[0;36mAbstractEnv._automatic_rendering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_video_wrapper\u001b[38;5;241m.\u001b[39mvideo_recorder\u001b[38;5;241m.\u001b[39mcapture_frame()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/highway_env/envs/common/abstract.py:308\u001b[0m, in \u001b[0;36mAbstractEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39mhandle_events()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 308\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image\u001b[49m()\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_image'"
     ]
    }
   ],
   "source": [
    "\n",
    "GENERATIONS = 1000\n",
    "SEEDS_PER_GEN = 2\n",
    "MODELS = 10\n",
    "OBS_SIZE = env.unwrapped.config[\"observation\"][\"vehicles_count\"] * len(env.unwrapped.config[\"observation\"][\"features\"])\n",
    "\n",
    "models = [Model(OBS_SIZE, ACTION_SIZE) for i in range(MODELS)]\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    env.unwrapped.config[\"duration\"] = 8 + 0.5 * generation\n",
    "    print(f'Generation: {generation}')\n",
    "    # create models\n",
    "\n",
    "    scores = [0 for i in range(MODELS)]\n",
    "\n",
    "    for i in range(SEEDS_PER_GEN):\n",
    "        seed = np.random.randint(1_000_000)\n",
    "        for model_num in range(MODELS):\n",
    "            print(f'{model_num} ', end='')\n",
    "            render = False\n",
    "            if model_num % 1 == 0:\n",
    "                render = True\n",
    "            model = models[model_num]\n",
    "\n",
    "            env.reset(seed=seed)\n",
    "            done = truncated = False\n",
    "            obs = None\n",
    "            score = 0\n",
    "            while not (done or truncated):\n",
    "                probabilities = model(obs).view(-1).detach().numpy()\n",
    "                action = np.argmax(probabilities)\n",
    "                # action = np.random.choice(ACTION_SIZE, p=probabilities)\n",
    "                obs, reward, done, truncated, info = env.step(action)\n",
    "                if info[\"rewards\"][\"on_road_reward\"] == 0:\n",
    "                    # reward -= 10\n",
    "                    done = True\n",
    "                if render:\n",
    "                    env.render()\n",
    "                # score += reward\n",
    "                score += obs[0][2]\n",
    "            print(score)\n",
    "            # print(obs)\n",
    "\n",
    "            # if done:\n",
    "            #     score -= 10\n",
    "\n",
    "            scores[model_num] += score\n",
    "            # scores[model_num] += score\n",
    "        print()\n",
    "    best_score = max(scores)\n",
    "    best_model_num = scores.index(best_score)\n",
    "    best_model = models[best_model_num]\n",
    "    print(f'Best model_num: {best_model_num} | score: {best_score}\\n')\n",
    "    models = [copy.deepcopy(best_model) for i in range(MODELS)]\n",
    "    change = 0.01 * (0.999 ** generation)\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.data += change * torch.randn_like(param)\n",
    "    torch.save(best_model.state_dict(), f'model_gen{generation}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
